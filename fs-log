#! /usr/bin/python2.5 -u

import os, sys, hashlib, dircache, time, csv, stat
#import wx
#import gtk, pygtk
#import cProfile
#import pstats
from stat import *


class FileType:
    directory, file = range(2)

class FileStatus:
    updated, new, erased = range(3)
    
class FileInfo(object):
    class ValidationError(Exception):
        def __init__(self, error_code):
            self.error_code = error_code

    def __init__(self, file_attributes, check = False):
        if check == False:
            self.__init_attr(file_attributes)
        else:
            self.__check_and_init(file_attributes)

    def __init_attr(self, file_attributes):
        self.type = int(file_attributes[0])
        self.name = file_attributes[1]
        self.size = int(file_attributes[2])
        self.modify_date = int(file_attributes[3])
        if len(file_attributes) == 5:
            self.hash = file_attributes[4]
    
    def __check_and_init(self, file_attributes):
        error_code = self.__check_hist_file_entry(file_attributes)
        if error_code == 0:    
            self.__init_attr(file_attributes)
        else:
            raise self.ValidationError(error_code)

    def __check_size(self, size):
        try:
            size = int(size)
        except:
            return(False)
        if size < 0:
            return(False)
        return(True)

    def __check_modify_date(self, modify_date):
        try:
            modify_date = int(modify_date)
        except:
            print "cast error"
            return(False)
        #print "int_cast: ",int(execution_time)
        return(modify_date < (int(execution_time)))

    def __check_hash(self, hash_string):
        if len(hash_string) == 64:
            for letter in hash_string:
                if not ((letter >= '0' and letter <= '9')
                        or (letter >= 'a' and letter <= 'f')): 
                    return(False)
            return(True)
        return(False)
    
    def __check_filename(self, filename):
        if len(filename) <= 256:
            for letter in filename:
                if letter == '/':
                    return(False)
            return(True)
        return(False)

    def __check_hist_file_entry(self, file_attributes):
        error_code = 0
        if len(file_attributes) != 5:
            error_code = 8
        if not (int(file_attributes[0]) in range(2)):
            error_code = 1
        if not self.__check_filename(file_attributes[1]):
            error_code = 2
        if file_attributes[2] < 0:
            error_code = 3
        #if int(file_attributes[3]) > int(execution_time):
        if not self.__check_modify_date(file_attributes[3]):
            error_code = 4
        if not self.__check_hash(file_attributes[4]):
            error_code = 5
        return(error_code)

    def get_attr_without_mod_hash_and_size(self):
        return(self.type, self.name)
    def get_attr_without_mod_and_hash(self):
        return(self.type, self.name, self.size)
    def get_attr_without_hash(self):
        return(self.type, self.name, self.size, self.modify_date)
    def get_attr(self):
        return(self.type, self.name, self.size, self.modify_date, self.hash)
    
    # allows sorting and comparing of the dir lists
    # sorting order is: type, name, size, modify_date
    def __lt__(self, cmp_file):
        #return(self.get_attr_without_hash() < cmp_file.get_attr_without_hash())
        
        #if self.type == cmp_file.type:    
        #    if self.name < cmp_file.name:
        #        return(True)
        #else:
        #    if self.type < cmp_file.type:
        #        return(True)
        #return(False)

        return(self.get_attr_without_mod_hash_and_size() < cmp_file.get_attr_without_mod_hash_and_size())
    #def __eq__(self, cmp_file):
        #return(self.get_attr_without_hash() == cmp_file.get_attr_without_hash())
    #def __str__(self):
    #    return(get_attr())
    def __repr__(self):
        attr_string = ""
        for attr in self.get_attr_without_hash():
            attr_string += str(attr) + ',,'
        return(attr_string)
#def __getattr__
    #def __main__(self):
    #    return(get_attr())
#bla = file_info(1, 2, 3, 4)

def list_sorted(list, reversed=False):
    if len(list) > 1:
        #it_list = iter(list)
        first_loop = True
        for i in list:
            if first_loop:
                first_loop = False
            else:
                if reversed:
                    if i > last_item:
                        return(False)
                else:
                    if i < last_item:
                        return(False)
            last_item = i
    return(True)

def hash_file(filename):
    block_size = 2 ** 16
    print "filename: ", filename,
    file_to_hash = open(filename, 'rb')
    file_stat = os.fstat(file_to_hash.fileno())
    blocks = file_stat[stat.ST_SIZE] / block_size + 1
    print "; size: ", file_stat[stat.ST_SIZE],
    hash = hashlib.sha256()
    start_time = time.time()
    while blocks > 0:
        blocks -= 1
        hash.update(file_to_hash.read(block_size))
    print "; time: ", time.time() - start_time
    return(hash)

def get_dir_list_from_fs(directory):
    #print directory
    dir_content = []
    #file_type, file_size
    #a = dir
    if os.path.isdir(directory):
        for file in os.listdir(directory):
            file_stat = os.stat(directory + '/' + file)
            if S_ISDIR(file_stat[ST_MODE]):
                file_type = FileType.directory
                file_size = 0
                #new_dir = directory
            elif S_ISREG(file_stat[ST_MODE]):
                file_type = FileType.file
                file_size = file_stat[ST_SIZE]
            else:
                print "unsupported filetype: ", file
                continue
            dir_content.append(FileInfo((file_type,
                                         file,
                                         file_size,
                                         file_stat[ST_MTIME])))
    else:
        raise
    if not list_sorted(dir_content):
        print "directory content in unsorted state" 
        dir_content.sort()
    return(dir_content)

def get_latest_hist_time(directory):
    latest_time = 0
    if os.path.isdir(directory):
        for file in os.listdir(directory):
            if os.path.isfile(directory + '/' + file) and file.startswith('dirhash_'):
                file_time = int(file.lstrip('dirhash_'))
                if (latest_time < file_time):
                    latest_time = file_time    
    return(latest_time)

def get_dir_list_from_hist_file(directory):
    dir_content = []
    hist_time = get_latest_hist_time(directory)
    hist_file = directory + '/' + "dirhash_" + str(hist_time)
    if hist_time != 0:
        hist_reader = csv.reader(open(hist_file, "rb"),
                                 delimiter='/',
                                 quoting=csv.QUOTE_NONE)
        line_number = 1
        for row in hist_reader:
            try:                
                new_file_entry = FileInfo(row, True)
                dir_content.append(new_file_entry)
            except FileInfo.ValidationError, val:
                print "Validation error in history file"
                print "  file name:    ", hist_file
                print "  line number:  ", line_number
                print "  error number: ", val.error_code
                print "  field dump:"
                field_no = 1
                for field in row:
                    print "    ",field_no,": ",field
                    field_no += 1
                raise
            
            line_number += 1
    else:
        print "no history file found in directory: ", directory
    if not list_sorted(dir_content):
        dir_content.sort()
        print "history file in unsorted state"
    return(dir_content)

def compare_dir(fs_directory, hist_directory):
    dir_content = get_dir_list_from_fs(fs_directory)
    hist_content = get_dir_list_from_hist_file(hist_directory)
    diff = []
    dir_pos = hist_pos = 0
    dir_it = iter(dir_content)
    hist_it = iter(hist_content)
    if len(dir_content) > 0 and len(hist_content):
        dir_item = dir_it.next()
        hist_item = hist_it.next()
    for dir_item in dir_content:
        

    raise
    

def compare_dir_old(fs_directory, hist_directory):
    dir_content = get_dir_list_from_fs(fs_directory)
    hist_content = get_dir_list_from_hist_file(hist_directory)
    diff = []
    dir_pos = hist_pos = 0
    while (dir_pos < len(dir_content)) and (hist_pos < len(hist_content)):
        #compare file attributes without hash and modify date
        dir_entry = (dir_content[dir_pos].type, dir_content[dir_pos].name)
        hist_entry = (hist_content[hist_pos].type, hist_content[hist_pos].name)
        if dir_entry == hist_entry:
            #check if modify date of the file is newer than the entry in the history file
            if dir_content[dir_pos].modify_date > hist_content[hist_pos].modify_date:
                diff.append((FileStatus.updated, dir_content[dir_pos]))
            hist_pos += 1
            dir_pos += 1
        #check if the file is new on the filesystem
        elif dir_entry < hist_entry:
            diff.append((FileStatus.new, dir_content[dir_pos]))
            dir_pos += 1
            
        #file has been erased.
        else:
            diff.append((FileStatus.erased, hist_content[hist_pos]))
            hist_pos += 1
    for file in dir_content[dir_pos:]:
        diff.append((FileStatus.new, file))
    for file in hist_content[hist_pos:]:
        diff.append((FileStatus.erased, file))
    return(diff, dir_content, hist_content)

def hash_dir_list(dir_list):
    hash = hashlib.sha256()
    for dir_entry in dir_list:
        #hash all file attributes without modification date
        hash.update(str(dir_entry.type))
        hash.update(dir_entry.name)
        hash.update(str(dir_entry.size))
        hash.update(dir_entry.hash)
    return(hash)

def write_hist(has_changed, hist_directory, file_list):
    hist_filename = "dirhash_" + str(execution_time)
    if os.path.isdir(hist_directory) == False:
        os.makedirs(hist_directory)
        last_hist_time = 0
    else:
        last_hist_time = get_latest_hist_time(hist_directory)

    if os.path.isfile(hist_directory + '/' + hist_filename) == True:
        print "error. history file exists: ", hist_filename
    #elif has_changed == True or last_hist_time == 0:
    else:    
        #write new history file
        hist_file = open(hist_directory + '/' + hist_filename, 'a')
        hist_file.close()
        hist_writer = csv.writer(open(
                hist_directory + '/' + hist_filename, "wb"),
                delimiter='/',
                quoting=csv.QUOTE_NONE)
        #print file_list
        for file in file_list:
            hist_writer.writerow(file.get_attr())
    #else:
        #create filesystem link to the last version
        #pass

#def update_hist_for_sub_dirs()

def update_hist(fs_directory, hist_directory):
    hist_has_changed = False
    diff = compare_dir(fs_directory, hist_directory)
    print fs_directory
    if len(diff[0]) != 0:
        #print " ", diff[0]
        hist_has_changed = True
        hist_length = len(diff[2])
        hist_pos = 0
        for file in diff[0]:
            if file[0] == FileStatus.new:
                if file[1].type == FileType.file:
                    #only calculate hash for files.
                    #directories will be handled recursively at
                    #the end.
                    file[1].hash = hash_file(fs_directory
                                             + '/'
                                             + file[1].name).hexdigest()
                diff[2].append(file[1])
            else:
                #find the right position to erase or update an list item.
                while (hist_pos < hist_length):
                    if (file[1].get_attr_without_mod_hash_and_size() ==
                        diff[2][hist_pos].get_attr_without_mod_hash_and_size()):
                        if file[0] == FileStatus.erased:
                            #erase from new history file.
                            del diff[2][hist_pos]
                            hist_length -= 1
                        elif file[0] == FileStatus.updated:
                            #update entry.
                            diff[2][hist_pos] = file[1]
                            if diff[2][hist_pos].type == FileType.file:
                                #only hash files. not directories.
                                diff[2][hist_pos].hash = hash_file(fs_directory
                                                         + '/'
                                                         + diff[2][hist_pos].name).hexdigest()
                        else:
                            print "unknown file status"
                        break
                    else:
                        hist_pos += 1
        if not list_sorted(diff[2]):
            diff[2].sort()
    #recursively call the function for every directory
    dir_count = 0
    file_count = 0
    for file in diff[2]:
        if file.type == FileType.directory:
            dir_count += 1
            sub_dir = update_hist(fs_directory + '/' + file.name,
                                  hist_directory + '/' + file.name)
            sub_dir_has_changed = False
            if hasattr(file, "hash") == False:
                sub_dir_has_changed = True
            elif sub_dir[3] != file.hash:
                sub_dir_has_changed = True
            if sub_dir_has_changed:
                #sub directory is new or content has changed
                file.size = sub_dir[1] + sub_dir[2]
                file.hash = sub_dir[3]
                hist_has_changed = True
            dir_count += sub_dir[1]
            file_count += sub_dir[2]
        else:
            file_count += 1
    if hist_has_changed:
        write_hist(hist_has_changed, hist_directory, diff[2])    
    return(hist_has_changed, 
           dir_count, 
           file_count, 
           hash_dir_list(diff[2]).hexdigest())

def check_for_hash_collision(same_hashes):
    for same in same_hashes:
        first_file = True
        for file in same:
            if first_file:
                first_file = False
                size = os.path.getsize(file)
            elif os.path.getsize(file) != size:
                print "Found hash collision for sha256!"
                print "Please contact a cryptography expert near you."
                print "Files:"
                print "  ",same[0]
                print "  ",file
                #raise
                    
    

#find files and directories with same hash value
def find_same_hashes(directory, min_size, same_hashes, hashes={}, recursion_depth=0):
    print directory
    dir_list = get_dir_list_from_hist_file(directory)
    for file in dir_list:
        hash_entry = False
        if file.type == FileType.file:
            if file.size >= min_size:
                hash_entry = True
        elif file.type == FileType.directory:
            if file.size > 0:
                hash_entry = True
                find_same_hashes(directory + '/' + file.name,
                                 min_size,
                                 same_hashes,
                                 hashes,
                                 recursion_depth + 1)
        else:
            print "unknown file type"
        if hash_entry:
            if file.hash in hashes:
                if not file.hash in same_hashes:
                    same_hashes[file.hash] = [hashes[file.hash]]
                same_hashes[file.hash].append((recursion_depth, file.type, directory + '/' + file.name))
            else:
                hashes[file.hash] = (recursion_depth, file.type, directory + '/' + file.name)
    return()

def group_same_hashes(same_hashes):
    grouped_hashes={}
    for same_files in same_hashes.values():
        print same_files
        if same[1][0][0] == FileType.directory:
            for same_file in same[1]:
                pass





if len(sys.argv[1:]) != 3:
    print 'error'
    sys.exit(1)
    pass

execution_time = str(time.time()).partition('.')[0]
print "execution time:",int(execution_time)
print "arguments:"
for i in range(len(sys.argv)):
    print "arg", i, sys.argv[i]
print
#try:
summary = update_hist("files", "hist")
    #summary = update_hist("/media/fs_hist", "hist")
    #print summary
print "---"
same_files = {}
find_same_hashes("hist", int(sys.argv[1]), same_files)
#group_same_hashes(same_files)

for i in same_files.items ():
    print i[0]
    for file in i[1]:
        print "  ",file
print len(same_files)

#a = get_dir_list_from_hist_file("hist/list_test")
#print a
#except Exception:
#    print
#    print "aborted"
#    raise
